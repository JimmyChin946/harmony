services:
  api:
    build: 
      context: .
      dockerfile: docker/api/Dockerfile
    ports:
      - "5000:5000"
    volumes:
      - ./models:/models:ro
      - ./data:/data:ro
    environment:
      - MODEL_DIR=/models
      - PORT=5000
      - WEB_CONCURRENCY=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 16g
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    container_name: api

  tfs-lorcana:
    image: tensorflow/serving
    ports:
      - "8605:8605"
    volumes:
      - ./saved_models/lorcana/:/models/lorcana/
    command: >
      --model_config_file=/models/lorcana/tfs.config
      --model_config_file_poll_wait_seconds=60
      --rest_api_port=8605
    restart: unless-stopped
    container_name: tfs-lorcana

  tfs-pokemon:
    image: tensorflow/serving
    ports:
      - "8606:8606"
    volumes:
      - ./saved_models/pokemon/:/models/pokemon/
    command: >
      --model_config_file=/models/pokemon/tfs.config
      --model_config_file_poll_wait_seconds=60
      --rest_api_port=8606
    restart: unless-stopped
    container_name: tfs-pokemon

