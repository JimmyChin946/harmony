services:
  training:
    build:
      context: .
      dockerfile: ./docker/training/Dockerfile
    command: tail -f /dev/null
    environment:
      - PYTHONPATH=/harmony/src
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TF_CPP_MIN_LOG_LEVEL=1
      - TF_CUDNN_DETERMINISTIC=true
      - TF_XLA_FLAGS=--tf_xla_enable_xla_devices
    env_file: 
      - path: ./.env
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./data/:/volumes/data/
      - ./keras_models/:/volumes/keras_models/
      - ./saved_models/:/volumes/saved_models/
      - ./config/:/volumes/config/
    runtime: nvidia
    restart: no 
    container_name: training 

  api:
    build: 
      context: .
      dockerfile: docker/api/Dockerfile
    environment:
      - PYTHONPATH=/harmony/src
      - PYTHONUNBUFFERED=1
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    env_file:
      - path: ./.env
    ports:
      - "${API_PORT}:5000"
    volumes:
      - ./data/:/volumes/data/
      - ./keras_models/:/volumes/keras_models/
      - ./saved_models/:/volumes/saved_models/
      - ./config/:/volumes/config/
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    restart: unless-stopped
    container_name: api

  tfs-lorcana:
    image: tensorflow/serving:latest-gpu
    environment: 
      - NVIDIA_VISIBLE_DEVICES=all
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    ports:
      - "${LORCANA_PORT}:8501"
    volumes:
      - ./saved_models/lorcana/:/models/lorcana/
      - ./batching_parameters.txt:/batching_parameters.txt
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    command: >
      --model_config_file=/models/lorcana/tfs.config
      --model_config_file_poll_wait_seconds=60
      --enable_batching
      --batching_parameters_file=/batching_parameters.txt
    restart: unless-stopped
    container_name: tfs-lorcana

  tfs-pokemon:
    image: tensorflow/serving:latest-gpu
    environment: 
      - NVIDIA_VISIBLE_DEVICES=all
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    ports:
      - "${POKEMON_PORT}:8501"
    volumes:
      - ./saved_models/pokemon/:/models/pokemon/
      - ./batching_parameters.txt:/batching_parameters.txt
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    command: >
      --model_config_file=/models/pokemon/tfs.config
      --model_config_file_poll_wait_seconds=60
      --enable_batching
      --batching_parameters_file=/batching_parameters.txt
    restart: unless-stopped
    container_name: tfs-pokemon

